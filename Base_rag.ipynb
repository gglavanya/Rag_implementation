{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96100841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9679e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the PDF file using PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_pdf(file_path: str):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load()\n",
    "\n",
    "    print(f\"Total Pages Found: {len(pages)}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Content of Page 1 (First 500 chars):\\n{pages[0].page_content[:500]}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Metadata of Page 1: {pages[0].metadata}\")\n",
    "\n",
    "    return pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bbb39ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pages Found: 8\n",
      "------------------------------\n",
      "Content of Page 1 (First 500 chars):\n",
      "Candidate:  Gurudevi  Lavanya  Gopisetty  \n",
      " \n",
      "1.  Personal  &  Academic  Overview  \n",
      "â—  Full  Name:  Gurudevi  Lavanya  Gopisetty  â—  Date  of  Birth  (DOB):  june  10  ,  1999  â—  Location:  Long  Beach,  California,  USA  â—  Email:  gglavanya06@gmail.com  â—  Phone:  +1  (669)  306-3851  \n",
      "Education  \n",
      "â—  Masterâ€™s  Degree:  M.S.  in  Computer  Science  â—  University:  California  State  University  â—  Expected  Graduation:  December  2025  â—  Cumulative  GPA:  3.909  /  4.0  \n",
      " \n",
      "2.  Professional  Ro\n",
      "------------------------------\n",
      "Metadata of Page 1: {'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Rag_docs', 'source': 'Rag_docs.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "my_pages=load_pdf('Rag_docs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3475951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the chunks to give to the vector database\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def create_chunks(text):\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = splitter.split_documents(text)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc433c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created 20 chunks.\n",
      "First chunk preview: Candidate:  Gurudevi  Lavanya  Gopisetty  \n",
      " \n",
      "1.  Personal  &  Academic  Overview  \n",
      "â—  Full  Name:  G\n"
     ]
    }
   ],
   "source": [
    "my_chunks=create_chunks(my_pages)\n",
    "\n",
    "\n",
    "print(f\"âœ… Created {len(my_chunks)} chunks.\")\n",
    "print(f\"First chunk preview: {my_chunks[0].page_content[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bfacb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the chunks into embbedings into numerical form, so it can understand\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def get_embeddings_model():\n",
    "    model_name= \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    model_kwargs = {\"device\": \"cpu\"}\n",
    "    encode_kwargs={'normalize_embeddings': False}\n",
    "\n",
    "    return HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs) \n",
    "\n",
    "embed_model= get_embeddings_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb450007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embedding Successful!\n",
      "Vector Length: 384\n",
      "First 5 numbers of the vector: [-0.021258514374494553, 0.03264220803976059, -0.05218735337257385, -0.006472242064774036, 0.06284356117248535]\n"
     ]
    }
   ],
   "source": [
    "test_text = \"This is a test to see what a vector looks like.\"\n",
    "vector = embed_model.embed_query(test_text)\n",
    "\n",
    "print(f\"âœ… Embedding Successful!\")\n",
    "print(f\"Vector Length: {len(vector)}\") # Should be 384 for MiniLM\n",
    "print(f\"First 5 numbers of the vector: {vector[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4d2d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now storing the embeddings into a vector database where it can be stored according to its value and positions and can get the similarity by distance calculation\n",
    "from langchain_chroma import Chroma \n",
    "def create_vector_db(chunks, embed_model):\n",
    "    vector_db = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embed_model,\n",
    "        persist_directory=\"./vector_db\"\n",
    "    )\n",
    "    return vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ff51c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TOP SEARCH RESULT ---\n",
      "Content: Candidate:  Gurudevi  Lavanya  Gopisetty  \n",
      " \n",
      "1.  Personal  &  Academic  Overview  \n",
      "â—  Full  Name:  Gurudevi  Lavanya  Gopisetty  â—  Date  of  Birth  (DOB):  june  10  ,  1999  â—  Location:  Long  Beac...\n",
      "Metadata: {'producer': 'Skia/PDF m145 Google Docs Renderer', 'title': 'Rag_docs', 'creator': 'PyPDF', 'page': 0, 'source': 'Rag_docs.pdf', 'creationdate': '', 'page_label': '1', 'total_pages': 8}\n"
     ]
    }
   ],
   "source": [
    "vector_db = create_vector_db(my_chunks, embed_model)\n",
    "\n",
    "# --- INSPECTION: The \"Similarity Search\" Test ---\n",
    "# Let's see if it can find the right chunk without an LLM\n",
    "query = \"What is the name of the person?\" # Change this to a topic in your PDF\n",
    "search_results = vector_db.similarity_search(query, k=2) # Get top 2 matches\n",
    "\n",
    "print(\"\\n--- TOP SEARCH RESULT ---\")\n",
    "print(f\"Content: {search_results[0].page_content[:200]}...\")\n",
    "print(f\"Metadata: {search_results[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe3393c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def get_answer(question, vector_db):\n",
    "    llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "\n",
    "    # 1. Define the prompt\n",
    "    template = template = \"\"\"\n",
    "    You are a professional and friendly career assistant. \n",
    "    Your goal is to answer questions about a candidate's skills based on their resume/profile data.\n",
    "    your goal is to answer the question as if the candidate answers to the requiterer.\n",
    "\n",
    "    RULES:\n",
    "    1. Do NOT say \"Based on the context\" or \"According to the document.\"\n",
    "    2. Speak as if you already know the candidate well.\n",
    "    3. Use a friendly, conversational, and professional tone.\n",
    "    4. If the information isn't there, politely say you aren't sure about that specific detail.\n",
    "    5. Keep it concise but enthusiastic.\n",
    "    6. If you don't have enough information to answer, ask for clarification.\n",
    "    7. if the question is ask about a job/role she fits in, i want you to answer accordingly , and also put the skills and relevant projects worked on.\n",
    "    8. start the sentence like  \"Lavanya did this, Lavanya did that, Lavanya is a professional in this field, Lavanya has worked on this project, Lavanya is skilled in this area.\"\n",
    "    9. if the question is ask about a job/role she fits in, i want you to answer accordingly , and also put the skills and relevant projects worked on.\n",
    "\n",
    "    Candidate Information:\n",
    "    {context}\n",
    "    \n",
    "    User Question: {question}\n",
    "    Friendly Response:\n",
    "   \n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # 2. Build the chain using the \"Pipe\" | operator\n",
    "    # This says: Get context -> Pass to prompt -> Pass to LLM -> Parse as string\n",
    "    chain = (\n",
    "        {\"context\": vector_db.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 3. Run it\n",
    "    return chain.invoke(question)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d79687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– AI ANSWER:\n",
      "Lavanya has a solid understanding of Machine Learning fundamentals, with strong applied knowledge and mathematical intuition behind models. She's well-versed in the theory-to-practice alignment of ML, including Data Structures & Algorithms, Operating Systems, Finite Automata, Machine Learning, Deep Learning, Artificial Intelligence, Probability, & Statistics.\n",
      "\n",
      "She also has experience working on projects related to Machine Learning, such as developing predictive models using Python libraries like Scikit-Learn and TensorFlow.\n"
     ]
    }
   ],
   "source": [
    "answer = get_answer(\"does candidate know machine learning , is she good in it \" \\\n",
    "\"\", vector_db)\n",
    "print(f\"ðŸ¤– AI ANSWER:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692cb45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
